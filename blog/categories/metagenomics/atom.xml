<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: metagenomics | bio(logist | informatician)]]></title>
  <link href="http://ctSkennerton.github.io/blog/categories/metagenomics/atom.xml" rel="self"/>
  <link href="http://ctSkennerton.github.io/"/>
  <updated>2015-10-03T02:44:16-07:00</updated>
  <id>http://ctSkennerton.github.io/</id>
  <author>
    <name><![CDATA[Connor Skennerton]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Finding 16s/18s reads in metagenomes]]></title>
    <link href="http://ctSkennerton.github.io/blog/2014/04/19/rRNA-read-extraction-from-metagenomes/"/>
    <updated>2014-04-19T22:51:00-07:00</updated>
    <id>http://ctSkennerton.github.io/blog/2014/04/19/rRNA-read-extraction-from-metagenomes</id>
    <content type="html"><![CDATA[<p>Got a Metagenome? want to know what the community looks like?</p>

<!-- more -->


<p>rRNA operons are typically poorly assembled in metagenomic datasets due to
highly conserved sequences.  More targeted assembly approaches may be necessary
to obtain accurate reconstructions from short read datasets. There are a few
ways in which we can extract reads originating from either 16S or 18S reads and
there are a number of programs (<a href="http://selab.janelia.org/software/ssu-align/">SSU-ALIGN</a>,
<a href="http://www.ncbi.nlm.nih.gov/pubmed/21887657">rRNASelector</a>,
<a href="http://ribopicker.sourceforge.net/">riboPicker</a>,
<a href="http://bioinfo.lifl.fr/RNA/sortmerna/">SortMeRNA</a>,
blast, <a href="http://bowtie-bio.sourceforge.net/bowtie2/index.shtml">bowtie</a> or <a href="https://github.com/lh3/bwa">bwa</a>) to name a few.</p>

<p>There are a other ways of looking at the communty from raw metagenomic
reads. These are mostly kmer-based approaches like
<a href="http://ccb.jhu.edu/software/kraken/">kraken</a> or extended marker gene
approaches like
<a href="http://huttenhower.sph.harvard.edu/metaphlan">MetaPhlAn</a> or
<a href="http://phylosift.wordpress.com/">phylosift</a>. I&rsquo;m not against any of
them, just never used them, so I&rsquo;m going to keep the following post
specific to 16s/18s community composition</p>

<h2>Extracting 16S/18S reads</h2>

<p>I&rsquo;ve used SortMeRNA and bowtie/bwa in my workflows with good success. The
difference between these two methods is that SortMeRNA that uses a kmer
searching method using an index created from a database of previously sequenced
genes whereas bowtie/bwa use a local alignment method to compare the query sequence to
a previously made database. Below are instructions on how to use both methods.</p>

<h2>Installing and using SortMeRNA</h2>

<p>From the source page for SortMeRNA on <a href="https://github.com/biocore/sortmerna">github</a>
copy the ssh clone url and then open up a terminal window and type
<code>bash
$ git clone git@github.com:biocore/sortmerna.git
$ cd sortmerna
$ ./configure --prefix=$PWD
$ make install
</code>
<strong>Mac OSX install note:</strong> I found that there was an error with my install
with <code>configure</code> complaining that it was missing <code>install-sh</code>. I solved this by
copying <a href="http://sourceforge.net/projects/buildconf/">autogen.sh</a> into the same
directory as <code>configure</code>, execute it and then try running configure again.</p>

<p>The commands above should install SortMeRNA in the directory which you downloaded
it to.</p>

<h4>Building indexes for SortMeRNA</h4>

<p>SortMeRNA comes packaged with 8 different rRNA databases, all derived from SILVA.
Build either the 16S or 18S database, depending on what you want. Below is the
command used to generate the 18S index (assuming that you&rsquo;ve installed in the
download directory)
<code>bash
$ bin/indexdb_rna --ref rRNA_databases/silva-euk-18s-database-id95.fasta,index/silva-euk-18s-database-id95 --sensitive
</code>
If you <code>ls</code> the index directory you should see four files generated.</p>

<h4>Preprocessing reads</h4>

<p>Now we can use this index to extract the reads that may come from 18S using the
<code>sortmerna</code> command. I&rsquo;m going to assume that there are files containing raw
reads from an Illumina run called <code>file_R1.fastq.gz</code> and <code>file_R2.fastq.gz</code>.
Unfortunately one of the limitations of SortMeRNA is that it requires that you
only give it a single file and that the file is uncompressed. So to start with,
unzip the files using <code>gzip</code> and then combine them into a single file using
<code>merge-paired-reads.sh</code> found in the scripts directory of the SortMeRNA source
code
<code>bash
$ gunzip file_R1.fastq.gz file_R2.fastq.gz
$ bash scripts/merge-paired-reads.sh file_R1.fastq file_R2.fastq combined.fastq
</code>
To save space, it&rsquo;s probably best to re-zip the files to save on harddrive space
<code>bash
$ gzip file_R1.fastq file_R2.fastq
</code></p>

<h4>Extracting the reads</h4>

<p>Now we can run <code>sortmerna</code>, saving matched reads (and their mates) to a file
with the prefix &lsquo;matched-18S&rsquo; in fastq format using 4 processors.
```bash
$ bin/sortmerna &mdash;reads combined.fastq \</p>

<pre><code>--ref rRNA_databases/silva-euk-18s-database-id95.fasta,index/silva-euk-18s-database-id95 \
--paired-in \
--fastx \
--aligned matched-18S \
-a 4
</code></pre>

<p>```</p>

<h2>Installing and using BWA</h2>

<p>My personal preference is to use bwa over bowtie but the merits of either are
debatable (there are also 50 other programs out there that try to solve the same
problem so the choice is yours). Download bwa from <a href="https://github.com/lh3/bwa">github</a>
by copying the ssh clone url and typing the following into the terminal. (Change
directories out of the SortMeRNA source directory before you do this)
<code>bash
$ git clone git@github.com:lh3/bwa.git
$ cd bwa
$ make
</code>
bwa also requires that an index of the database be made. For simplicity, lets
use the same database that was included in SortMeRNA. To make the bwa index
copy the files that you want from the SortMeRNA source directory into a new
location.
<code>bash
$ cp ../sortmerna/rRNA_databases/silva-euk-18s-database-id95.fasta .
$ bwa index silva-euk-18s-database-id95.fasta
</code>
This should make a whole bunch of files that have extra file extensions appended
to the fasta file. With the index created we can now align the reads
<code>bash
$ bwa mem silva-euk-18s-database-id95.fasta file_R1.fastq.gz file_R2.fastq.gz &gt; aligned_18S.sam
</code>
(Notice that there is no preprocessing steps necessary for the reads)</p>

<h4>Postprocessing the sam file</h4>

<p>The output of bwa is a standardized format called <a href="http://samtools.github.io/hts-specs/SAMv1.pdf">sam</a>
which many programs will now output. This format essentially describes the
alignment of each of the query sequences to the reference sequences. This is
not exactly what we want, which is the reads that were successful hits to the
reference in fasta/q format. To go from a sam file to a fasta/q file is a little
complicated (I wish it wasn&rsquo;t). To start with, download <a href="https://github.com/samtools/samtools">samtools</a>
and <a href="https://github.com/ctSkennerton/fxtract">fxtract</a> from github, and download
them into new source directories (bonus points for getting them installed without
a walkthrough). First convert the sam file into its equivalent binary format and
filter out unaligned sequences:
<code>bash
$ samtools view -SubF 4 aligned_18S.sam | samtools sort - aligned_18S &amp;&amp; samtools index aligned_18S.bam
</code>
Now get the names of all the reads that aligned:
<code>bash
$ samtools view aligned_18S.bam | cut -f 1 &gt;aligned_reads.txt
</code>
And finally extract those reads from the original fastq files:
<code>bash
$ fxtract -Hf aligned_reads.txt file_R1.fastq.gz file_R2.fastq.gz &gt;aligned_reads.fastq
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Genome Scaffolders Suck]]></title>
    <link href="http://ctSkennerton.github.io/blog/2013/12/11/genome-scaffolders-suck/"/>
    <updated>2013-12-11T22:51:00-08:00</updated>
    <id>http://ctSkennerton.github.io/blog/2013/12/11/genome-scaffolders-suck</id>
    <content type="html"><![CDATA[<p>Experiences using a variety of contig scaffolding tools. It was not a good experience.</p>

<!-- more -->


<p>Recently in our lab we&rsquo;ve been getting some Illumina mate-pair data to
improve some metagenomic assemblies.  The sequencing has been going
well and we&rsquo;ve been generating a good number of mate-pairs without too much
duplication, but we&rsquo;ve had quite a bit of trouble with the bioinformatic part
of actually using this data to improve the assemblies.  There are a number of
software tools available to link contigs together after an assembly has been
done, however many assume that you are scaffolding a genome not a <em>meta</em>genome.<br/>
One of my colleagues suggested that, as a group, we perform a comparison of these
programs to determine which is the best one to suit our needs.</p>

<p>We decided to test out <a href="http://www.ncbi.nlm.nih.gov/pubmed/21149342">sspace</a>,
<a href="http://www.ncbi.nlm.nih.gov/pubmed/22492642">grass</a>,
<a href="http://www.ncbi.nlm.nih.gov/pubmed/23274213">scarpa</a>,
<a href="http://www.ncbi.nlm.nih.gov/pubmed/21929371">opera</a>,
<a href="http://www.ncbi.nlm.nih.gov/pubmed/21998153">mip</a> and
<a href="http://www.ncbi.nlm.nih.gov/pubmed/21926123">bambus2</a>.
From these six programs, only bambus2 was designed for metagenomes.
To test how well genome scaffolders could transition into
metagenome scaffolders we took one of our metagenomes and randomly broke
up 1000 contigs formed only using paired-end data into two pieces and
attempted to use some shiny new mate-pair data to put the pieces back
together again.  Little did we know the world of pain that we were about
to step into&hellip;</p>

<p>The following post will not talk about which algorithm was better or even
really what results each of these programs gave.  No, I&rsquo;m going to talk
about why using all these programs sucked.</p>

<h2>The war of attrition</h2>

<h3>grass</h3>

<p>We didn&rsquo;t even get <em>grass</em> installed; it required a particular library
distributed by IBM, which while free for academic users, required you to
give over some personal details, which we decided was something that we
didn&rsquo;t want to do.</p>

<p>One down, five to go&hellip;</p>

<h3>mip</h3>

<p>Oh where do I start with <em>mip</em>! <em>Mip</em> assumes that you&rsquo;re using SOLiD
data, which means that it expects that the orientation of the reads are
forward-forward.  Since Illumina&rsquo;s mate-pairs are reverse-forward I
needed to reverse complement the first read, making a duplicate file.  But
actually I needed to modify the second read file as well because <em>mip</em>
needs to have the read identifiers ending in &ldquo;<em>R3&rdquo; or &ldquo;</em>F3&rdquo; (WTF!), just
like they would be for a SOLiD run.  After this, I could then run any short-read
mapper to produce a SAM file for further processing.  But wait, you have
to map each read separately (i.e. not as pairs) and then pass the SAM
file through two preprocessing shell scripts.  The first of these shell
scripts, the opaquely named <code>merge.sh</code> simply takes the corresponding
SAM alignment record from the first and second reads and concatenates
the lines!  Why this needed to be a separate script and not just part of
the software proper is beyond me. Both of these preprocessing scripts created new files that
were essentially duplicates of the original SAM files made by the
short-read mapper, which I truly find annoying, especially since our
server is currently short on storage space.</p>

<p>When I ran <em>mip</em> proper, it threw an error.  That error may have been
easy for me to fix, it might have been something silly that I had put
into <em>mip&rsquo;s</em> configuration file, I don&rsquo;t know.  At this point I was pissed
about the whole process and never tried to run the program again.</p>

<p>Two down, four to go&hellip;</p>

<h3>opera</h3>

<p>It segfaulted on the test data that came with the software.</p>

<p>Three down, three to go&hellip;</p>

<h3>bambus2</h3>

<p>I had hope for bambus, and this was the scaffolder which I put the most
amount of effort to get it to work.  The problem with bambus is
that it is part of the <a href="http://sourceforge.net/apps/mediawiki/amos/index.php?title=AMOS">AMOS</a>
software package and the problem with AMOS is that it is fairly old
and uses it&rsquo;s own file format.  I have no doubt that the authors of AMOS
were hoping that their file format would catch on and that many tools
would plug into it, but alas the AMOS file format did not catch on,
instead we have SAM files.  So I set about looking for a SAM to AMOS
file converter, and I found <a href="http://sourceforge.net/p/amos/code/ci/master/tree/src/Converters/samtoafg.pl">one</a>
in the AMOS package.  It was a nice little perl script that
unfortunately didn&rsquo;t work (once again threw an error).</p>

<p>I decided to write my own converter in C++ using the
<a href="https://github.com/pezmaster31/bamtools">bamtools</a> and AMOS C++ APIs.
The fruits of my labour was the program <a href="https://github.com/ctSkennerton/sam2amos">sam2amos</a>,
which can take a BAM file and convert it into either an AMOS message
stream or an AMOS bank.  I was honestly really impressed with the
simplicity of both of these APIs, which made writing this program
relatively easy.</p>

<p>After making my AMOS bank file with sam2amos I ran the <code>goBambus2.py</code> wrapping script,
which unfortunately resulted in bambus segfaulting. Bugger!  I didn&rsquo;t
have it in me to debug the situation and figure out whether it was caused by a problem in
sam2amos (which it probably is) or something else.</p>

<p>Four down, two to go&hellip;</p>

<h2>Finally some results</h2>

<h3>scarpa</h3>

<p>I never personally ran <em>scarpa</em> (one of my colleagues did) but it shared some of the
annoyances that <em>mip</em> had.  <em>Scarpa</em> assumes that the reads are in
forward-reverse orientation so it required that both of the reads be
reverse complemented before use.  Like <em>mip</em>, the reads needed to be
mapped independently.  But unlike <em>mip</em>, <em>scarpa</em> gave some results!!
Of course the output was a simple fasta file of scaffolds without any
indication of what contigs were actually put together.  A little more
information would have been nice&hellip;</p>

<h3>sspace</h3>

<p><em>Sspace</em> is the best of the bunch when it comes to usability.  You can
specify what orientation the reads were in and there was only one manual
preprocessing step required; <em>sspace</em> does not accept compressed files so
the reads had to be passed through <code>ungzip</code> before use.  <em>Sspace</em> does however have some annoying
automatic preprocessing steps. First, the reads are copied into the
output directory (why? I don&rsquo;t know). Second, <em>sspace</em> only runs bowtie,
you cannot specify any other mapper, this isn&rsquo;t so much of a problem but
it annoyingly repeats the mapping even if the results from a previous
run exist in the output directory.  The output though is better than
<em>scarpa&rsquo;s</em> as it gives you a fasta file of scaffolds, an &ldquo;evidence file&rdquo; actually
telling you how it put contigs together and optionally a graphviz file
so that you can look at the contig linkages.</p>

<h2>What I want from a scaffolder</h2>

<ol>
<li>The ability to take either a SAM or BAM file of read mappings; or</li>
<li>If a particular read mapper is really required, give me the ability
to set the read orientation and used commpressed input files</li>
<li>One that uses pipes and does not copy reads into an output
directory. The less file I/O the better</li>
<li>No configureation files, I want to pipeline this thing, give me some
command-line options</li>
<li>Tell me how the scaffolding was done with some sort of easy tabular
file format.  Better yet make that output format <a href="http://www.ncbi.nlm.nih.gov/projects/genome/assembly/agp/AGP_Specification.shtml">AGP</a>,
which is required by NCBI when uploading scaffolds.</li>
</ol>


<h2>Epilogue</h2>

<p>Oh yeah, <em>sspace</em> gave better results than <em>scarpa</em></p>
]]></content>
  </entry>
  
</feed>
